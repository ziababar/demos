{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_similarity.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNtxOSARJ2cD7iVxU8xz7Cy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ziababar/demos/blob/master/derivative_security/notebooks/image_similarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuIahsh1tXBS"
      },
      "source": [
        "# Background\n",
        "\n",
        "The objective of this notebook program is to find how similar two images are. This can be used to determine the derivative images from a source image.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hjjXXeEtfDT"
      },
      "source": [
        "# References\n",
        "\n",
        "The code in this notebook has been adapted from the following,\n",
        "\n",
        "1.   [Check if two images are equal with Opencv and Python](https://pysource.com/2018/07/19/check-if-two-images-are-equal-with-opencv-and-python/)\n",
        "2.   [Find similarities between two images with Opencv and Python](https://pysource.com/2018/07/20/find-similarities-between-two-images-with-opencv-and-python/)\n",
        "3.   [Detect how similar two images are with Opencv and Python](https://pysource.com/2018/07/20/detect-how-similar-two-images-are-with-opencv-and-python/)\n",
        "4.   [Check if a set of images match the original one with Opencv and Python](https://pysource.com/2018/07/27/check-if-a-set-of-images-match-the-original-one-with-opencv-and-python/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9hQSKzxunS_"
      },
      "source": [
        "# Libraries\n",
        "\n",
        "OpenCV\n",
        "NumPy\n",
        "PyPlot\n",
        "UrlLib\n",
        "CV2_IMSHOW\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFZ_x4Q5e3Ui"
      },
      "source": [
        "# We need to downgrade OpenCV as some none-free features are not available in the latest version\n",
        "# First uninstall OpenCV and then install the older version\n",
        "\n",
        "!pip uninstall opencv-python -y\n",
        "!pip install opencv-contrib-python==3.4.2.17 --force-reinstall\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGdkArnlP01g"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "from urllib.request import urlopen\n",
        "from google.colab.patches import cv2_imshow\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zC151CM7vOZD"
      },
      "source": [
        "# Data Sources\n",
        "\n",
        "Load several image files from the GitHub repository. These images are,\n",
        "\n",
        "*   The original image\n",
        "*   A copied image\n",
        "*   A mixed color image\n",
        "*   A sunburst image\n",
        "*   A textured image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAzuVrt7Py4z"
      },
      "source": [
        "We now download all the images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nndO4cQKbDp8"
      },
      "source": [
        "# download the image, convert it to a NumPy array, and then read\n",
        "def url_to_image(url):\n",
        "    resp = urlopen(url)\n",
        "    image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        "    return image\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UE5IIa9HapvF"
      },
      "source": [
        "# Download the original image\n",
        "original = url_to_image(\"https://raw.githubusercontent.com/ziababar/demos/master/derivative_security/data/original_golden_bridge-300x169.jpg\")\n",
        "cv2_imshow(original)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJYBtdUFbw0f"
      },
      "source": [
        "# Download the duplicate image\n",
        "duplicate = url_to_image(\"https://raw.githubusercontent.com/ziababar/demos/master/derivative_security/data/original_golden_bridge-300x169.jpg\")\n",
        "cv2_imshow(duplicate)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksSCKBwX7mcX"
      },
      "source": [
        "# Download the rotated image\n",
        "rotated = url_to_image(\"https://raw.githubusercontent.com/ziababar/demos/master/derivative_security/data/original_golden_bridge-169x300.jpg\")\n",
        "cv2_imshow(rotated)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmNPwnBeceBN"
      },
      "source": [
        "# Download the mixed color image\n",
        "mixed_colors = url_to_image(\"https://raw.githubusercontent.com/ziababar/demos/master/derivative_security/data/mixed_colors-1024x575.jpg\")\n",
        "cv2_imshow(mixed_colors)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBGmFa0NdlLp"
      },
      "source": [
        "# Download the sunburst image\n",
        "sunburst = url_to_image(\"https://raw.githubusercontent.com/ziababar/demos/master/derivative_security/data/sunburst-1024x575.jpg\")\n",
        "cv2_imshow(sunburst)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RgYqVy-dlYJ"
      },
      "source": [
        "# Download the textured the image\n",
        "textured = url_to_image(\"https://raw.githubusercontent.com/ziababar/demos/master/derivative_security/data/textured-1024x575.jpg\")\n",
        "cv2_imshow(textured)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBsvy5m9wh3G"
      },
      "source": [
        "# Image Processing\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpioGkXMP3Ov"
      },
      "source": [
        "There are multiple cases to consider when processing and comparing images.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmU25S8NxRo9"
      },
      "source": [
        "## Case 1 - Images are identical\n",
        "\n",
        "Images are identical if they meet the following criteria,\n",
        "\n",
        "1.   Image size is the same AND\n",
        "2.   Image channel is the same AND\n",
        "3.   The subtraction of both images results in a black image\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lb4-Oe-bP_sX"
      },
      "source": [
        "# Check if both images are the same size\n",
        "if original.shape == duplicate.shape:\n",
        "    print(\"The images have same size and channels\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNrLeS2_xzt7"
      },
      "source": [
        "# The operation cv2.subtract(image1, image2) simply subtract from each pixel of the first image, the value of the corresponding pixel in the second image.\n",
        "difference = cv2.subtract(original, duplicate)\n",
        "b, g, r = cv2.split(difference)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcqxwQ-Gx7fq"
      },
      "source": [
        "# A colored image has 3 channels (blue, green and red)\n",
        "# so the cv2.subtract() operation makes the subtraction for each single channel and we need to check if all the three channels are black.\n",
        "# If they are, we can say that the images are equal.\n",
        "\n",
        "if cv2.countNonZero(b) == 0 and cv2.countNonZero(g) == 0 and cv2.countNonZero(r) == 0:\n",
        "    print(\"The images are completely Equal\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvWhaxmfyS8U"
      },
      "source": [
        "If the images are equal, the result will be a black image (which means each pixel will have value 0).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIWhXFTayW5O"
      },
      "source": [
        "cv2_imshow(difference)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN4pw8oXQQyr"
      },
      "source": [
        "## Case 2 - Images are similar but not identical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmP6Rwh-QSPc"
      },
      "source": [
        "In some cases, the two derived image may not be identifical to the source image.\n",
        "\n",
        "Here we take multiple derived images, these have different filters appliede to it (sunburst, color changes, textured etc.)\n",
        "\n",
        "Through feature detection and feature matching, we can find derived images which are similar to the source image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIG1m61S5voH"
      },
      "source": [
        "Here an approach called Scale Invariant Feature Transform (SIFT) is used to extract keypoints and compute its descriptors.\n",
        "\n",
        " - Keypoints are locations in the image that are determined based on measures of their stability.\n",
        " - Descriptors are local image gradients at selected scale and rotation that describe each keypoint region.\n",
        "\n",
        "SIFT is based on a paper by D.Lowe, University of British Columbia in 2004. A tutorial on SIFT is given at https://docs.opencv.org/master/da/df5/tutorial_py_sift_intro.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqmeqCFbQhG9"
      },
      "source": [
        "# Construct a SIFT object\n",
        "sift = cv2.xfeatures2d.SIFT_create()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKC8Y5fh-eUU"
      },
      "source": [
        "sift.detect() function finds the keypoint in the images.\n",
        "sift.compute() function computes the descriptors from the keypoints we have found.\n",
        "OR\n",
        "sift.detectAndCompute() function finds both keypoints and descriptors in a single step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkI05kkueeCY"
      },
      "source": [
        "# Detect key points and descriptors both both images\n",
        "kp_1, desc_1 = sift.detectAndCompute(original, None)\n",
        "kp_2, desc_2 = sift.detectAndCompute(mixed_colors, None)\n",
        "kp_3, desc_3 = sift.detectAndCompute(rotated, None)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oV1wBQxT-5v0"
      },
      "source": [
        "OpenCV also provides cv.drawKeyPoints() function which draws the small circles on the locations of keypoints."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmCpu8Pumf5j"
      },
      "source": [
        "img=cv2.drawKeypoints(original, kp_1, img)\n",
        "cv2_imshow(img)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwUnjifk7_oR"
      },
      "source": [
        "img=cv2.drawKeypoints(rotated, kp_1, img)\n",
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QB-gNUcyQnwp"
      },
      "source": [
        "# Load FlannBasedMatcher which is the method used to find the matches between the descriptors of both the images.\n",
        "index_params = dict(algorithm=0, trees=5)\n",
        "search_params = dict()\n",
        "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "\n",
        "# Find the matches between the 2 images, which is stored in the array  ‘matches’.\n",
        "# The array will contain all possible matches, so many false matches as well.\n",
        "matches = flann.knnMatch(desc_1, desc_2, k=2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "getD8MjjQqJi"
      },
      "source": [
        "Apply the ratio test to select only the good matches. The quality of a match is define by the distance. The distance is a number, and the lower this number is, the more similar the features are.\n",
        "\n",
        "By applying the ratio test we can decide to take only the matches with lower distance, so higher quality.\n",
        " - Decreasing the ratio value will get high quality matches but fewer matches.\n",
        " - Increasing the ratio value will get more matches but many false positives."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sa5coEaGQtM0"
      },
      "source": [
        "good_points = []\n",
        "ratio = 0.8\n",
        "\n",
        "for m, n in matches:\n",
        "    if m.distance < ratio*n.distance:\n",
        "        good_points.append(m)\n",
        "\n",
        "# Find the number of good matches found\n",
        "print(len(good_points))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRt4HqOuMKtk"
      },
      "source": [
        "We can see the found matches of keypoints from both two images. Here the parameters are,\n",
        " - img1 – First source image.\n",
        " - keypoints1 – Keypoints from the first source image.\n",
        " - img2 – Second source image.\n",
        " - keypoints2 – Keypoints from the second source image.\n",
        " - matches1to2 – Matches from the first image to the second one, which means that keypoints1[i] has a corresponding point in keypoints2[matches[i]] ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1RWSU2ELAu9"
      },
      "source": [
        "result = cv2.drawMatches(original, kp_1, mixed_colors, kp_2, good_points, None)\n",
        "cv2_imshow(result)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}